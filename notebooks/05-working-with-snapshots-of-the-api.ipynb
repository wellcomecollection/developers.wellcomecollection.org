{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Working with snapshots of the API\n",
    "\n",
    "As we saw at the end of the last notebook, the API limits its responses to 10,000 total results - after that point, users are directed to work with the snapshots. For example, making a request to <https://api.wellcomecollection.org/catalogue/v2/works?pageSize=100&page=101> gives us:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"errorType\": \"http\",\n",
    "    \"httpStatus\": 400,\n",
    "    \"label\": \"Bad Request\",\n",
    "    \"description\": \"Only the first 10000 works are available in the API. If you want more works, you can download a snapshot of the complete catalogue: https://developers.wellcomecollection.org/docs/datasets\",\n",
    "    \"type\": \"Error\"\n",
    "}\n",
    "```\n",
    "\n",
    "Let's download a snapshot and see what it contains. In later notebooks, we'll make use of the file we're downloading here.\n",
    "\n",
    "**NB: The uncompressed snapshot is >10GB, so this will take a while to download! Make sure your machine has enough space before running this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import gzip\n",
    "import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urls for the snapshots can be found at <https://developers.wellcomecollection.org/docs/datasets>. We're going to work with the `works` snapshot, but all of the logic which follows should be extendable to the images snapshot on that page too!\n",
    "\n",
    "Let's start by establishing the url for the compressed snapshot file, and the path where the data is going to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_url = \"https://data.wellcomecollection.org/catalogue/v2/works.json.gz\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the URL ends with `.gz`, indicating that we're going to be downloading a _zipped_ version of the file, which will need to be unzipped later.\n",
    "\n",
    "We're going to create a new directory next to these notebooks called `data`, where the zipped file will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data\").resolve()\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "file_name = Path(snapshot_url).parts[-1]\n",
    "zipped_path = data_dir / file_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the file using the `requests` library, and save it to the path we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the file already exists before doing any work\n",
    "if not zipped_path.exists():\n",
    "\n",
    "    # make a request to the snapshot URL and stream the response\n",
    "    r = requests.get(snapshot_url, stream=True)\n",
    "    \n",
    "    # use the length of the response to create a progress bar for the download\n",
    "    download_progress_bar = tqdm(\n",
    "        unit=\"bytes\",\n",
    "        total=int(r.headers[\"Content-Length\"]),\n",
    "        desc=f\"Downloading {file_name}\",\n",
    "    )\n",
    "\n",
    "    # write the streamed response to our file in chunks of 1024 bytes\n",
    "    with open(zipped_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                download_progress_bar.update(len(chunk))\n",
    "\n",
    "        download_progress_bar.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the zipped file, we can create a path for the _unzipped_ data to be saved, and use the `gzip` library to unzip the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipped_path = zipped_path.with_suffix(\"\")\n",
    "\n",
    "# open the zipped file, and the unzipped file\n",
    "with gzip.open(zipped_path, \"rb\") as f_in, open(unzipped_path, \"wb\") as f_out:\n",
    "    # measure the length of the zipped file using `.seek()`\n",
    "    file_length = f_in.seek(0, io.SEEK_END)\n",
    "    unzip_progress_bar = tqdm(\n",
    "        unit=\"bytes\",\n",
    "        total=file_length,\n",
    "        desc=f\"unzipping {file_name}\",\n",
    "    )\n",
    "\n",
    "    # we used `.seek()` to move the cursor to the end of the file, so we need to\n",
    "    # move it back to the start before we can read the whole thing file\n",
    "    f_in.seek(0)\n",
    "\n",
    "    # read the zipped file in chunks of 1MB\n",
    "    for chunk in iter(lambda: f_in.read(1024 * 1024), b\"\"):\n",
    "        f_out.write(chunk)\n",
    "        unzip_progress_bar.update(len(chunk))\n",
    "\n",
    "    unzip_progress_bar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've now got a copy of the works snapshot, and we're ready to start exploring it!\n",
    "\n",
    "The snapshot is saved in [jsonl](http://jsonlines.org/) format; a variant of json where each line is a separate json object. This is a common format for large json files, as it allows the user to read the file line-by-line, rather than having to load the entire file into memory.\n",
    "\n",
    "Let's have a look at the first line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(zipped_path, 'rt') as f:\n",
    "    first_line = f.readline()\n",
    "\n",
    "print(first_line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That first line is a standalone json document - we can parse it using the `json` library and play around with the keys and values, just as we did with the API responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = json.loads(first_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work[\"title\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the works in the snapshot include _all_ of the fields which were available in the default API response, _and_ all of the optional fields too. The snapshots include the complete set of information we have about our works, and are a great way to get a complete picture of the collection.\n",
    "\n",
    "## Wrapping up\n",
    "\n",
    "Let's delete the snapshot we've downloaded, and wrap up all of the logic we've established so far into a single cell which we can copy and reuse in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipped_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_url = \"https://data.wellcomecollection.org/catalogue/v2/works.json.gz\"\n",
    "\n",
    "data_dir = Path(\"./data\").resolve()\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "file_name = Path(snapshot_url).parts[-1]\n",
    "zipped_path = data_dir / file_name\n",
    "unzipped_path = zipped_path.with_suffix(\"\")\n",
    "\n",
    "if not unzipped_path.exists():\n",
    "    if not zipped_path.exists():\n",
    "        r = requests.get(snapshot_url, stream=True)\n",
    "        download_progress_bar = tqdm(\n",
    "            unit=\"B\",\n",
    "            total=int(r.headers[\"Content-Length\"]),\n",
    "            desc=f\"downloading {file_name}\",\n",
    "        )\n",
    "        with open(zipped_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    download_progress_bar.update(len(chunk))\n",
    "        download_progress_bar.close()\n",
    "        \n",
    "    with gzip.open(zipped_path, \"rb\") as f_in, open(unzipped_path, \"wb\") as f_out:\n",
    "        unzip_progress_bar = tqdm(\n",
    "            unit=\"B\",\n",
    "            total=f_in.seek(0, io.SEEK_END),\n",
    "            desc=f\"unzipping {file_name}\",\n",
    "        )\n",
    "        f_in.seek(0)\n",
    "        for chunk in iter(lambda: f_in.read(1024 * 1024), b\"\"):\n",
    "            f_out.write(chunk)\n",
    "            unzip_progress_bar.update(len(chunk))\n",
    "    \n",
    "        unzip_progress_bar.close()\n",
    "    zipped_path.unlink()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Count how many lines exist in the file, without loading the entire file into memory.\n",
    "2. Load the first 10 lines of the file into memory, and print them out.\n",
    "3. Adapt the code to download the images snapshot instead, and repeat the exercises above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
